{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Kaggle Titanic Competition***\n",
    "\n",
    "Made by Rodolfo Amorim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary Imports\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras import *\n",
    "import numpy as np \n",
    "import os as os\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the csv input files\n",
    "\n",
    "train_df = pd.read_csv(os.path.abspath('train.csv'))  \n",
    "test_df = pd.read_csv(os.path.abspath('test.csv'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples in x_train:  891\n",
      "Number of features in x_train:  6\n"
     ]
    }
   ],
   "source": [
    "#Cleaning of the input data\n",
    "\n",
    "train_df2= train_df.drop(['PassengerId','Name','Ticket','Cabin','Embarked'], axis=1)\n",
    "values={'Age':np.mean(train_df2.iloc[:,3])}\n",
    "train_df2 = train_df2.fillna(value=values) #Filling in the NaN entries by the mean of the ages of the titanic passangers\n",
    "\n",
    "#Number of NaN's to check if the previous step was correct\n",
    "#nan_count = train_df2.isna().sum()\n",
    "#print(nan_count)\n",
    "#print('\\n')\n",
    "\n",
    "y_train = train_df2.iloc[:,0] #True outcomes\n",
    "x_train = train_df2.drop(['Survived'],axis=1) #Features\n",
    "\n",
    "x_train = pd.get_dummies(x_train, columns=['Sex'], drop_first=True,dtype=float) #One-hot encode the 'Sex' column \n",
    "x_train.iloc[:,0] = x_train.iloc[:,0].astype(float)\n",
    "\n",
    "#Rescaling the columns of the dataframe\n",
    "x_train.iloc[:,1] = x_train.iloc[:,1]/np.max(x_train.iloc[:,1])\n",
    "x_train.iloc[:,0] = x_train.iloc[:,0]/3 \n",
    "x_train.iloc[:,4] = x_train.iloc[:,4]/np.max(x_train.iloc[:,4]) \n",
    "\n",
    "print('Number of Samples in x_train: ', len(x_train))\n",
    "print('Number of features in x_train: ', len(x_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples in x_test:  418\n"
     ]
    }
   ],
   "source": [
    "#Cleaning of the x_test data\n",
    "\n",
    "teste_df2= test_df.drop(['PassengerId','Name','Ticket','Cabin','Embarked'], axis=1)\n",
    "values={'Age':np.mean(teste_df2.iloc[:,2]),'Fare':np.mean(teste_df2.iloc[:,5]) }\n",
    "teste_df2 = teste_df2.fillna(value=values) #Filling in the NaN entries by the mean of the ages and fares of the titanic passangers\n",
    "passengerID = test_df.iloc[:,0]\n",
    "\n",
    "x_test = teste_df2  #Features\n",
    "x_test = pd.get_dummies(x_test, columns=['Sex'], drop_first=True,dtype=float) #One-hot encode the 'Sex' column\n",
    "x_test.iloc[:,0] = x_test.iloc[:,0].astype(float)\n",
    "\n",
    "#Rescaling the columns of the dataframe\n",
    "x_test.iloc[:,1] = x_test.iloc[:,1]/np.max(x_test.iloc[:,1])\n",
    "x_test.iloc[:,0] = x_test.iloc[:,0]/3 \n",
    "x_test.iloc[:,4] = x_test.iloc[:,4]/np.max(x_test.iloc[:,4])\n",
    "\n",
    "print('Number of Samples in x_test: ', len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [100,200],\n",
    "    'max_features': ['auto', 'sqrt','log2'],\n",
    "    'max_depth' : [8,9,10],\n",
    "    'max_leaf_nodes': [3, 6],\n",
    "    'criterion' :['gini','entropy','log_loss']\n",
    "}\n",
    "\n",
    "#Performing gridsearch over all the possible Random Forest hyperparameters\n",
    "CVr = GridSearchCV(estimator= RandomForestClassifier(random_state=1), param_grid = param_grid, cv = 5)\n",
    "CVr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtaining the output and saving it to a submission csv\n",
    "\n",
    "model = RandomForestClassifier(random_state=1, n_estimators=CVr.best_params_['n_estimators'],max_features=CVr.best_params_['max_features'],max_depth=CVr.best_params_['max_depth'],criterion=CVr.best_params_['criterion'], max_leaf_nodes=CVr.best_params_['max_leaf_nodes'])\n",
    "model.fit(x_train, y_train)\n",
    "predictions = model.predict(x_test) #Survival predictions\n",
    "\n",
    "\n",
    "pred_df = pd.DataFrame(predictions, columns=['Survived'])\n",
    "prediction_df = pred_df.set_index(passengerID)\n",
    "prediction_df.to_csv('submission.csv',header=['Survived']) #Making the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
